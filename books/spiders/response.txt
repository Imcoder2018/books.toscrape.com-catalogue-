In this post you will learn how to:

Scrap items on their own page
Extract routes with relative URLs
Select elements by tag, class, partial class and siblings elements
Extract information from tables
Use callbacks to other Scrapy class methods

import scrapy
class SpiderSpider(scrapy.Spider):
    name = 'spider'
    allowed_domains = ['books.toscrape.com']
    start_urls = ['http://books.toscrape.com/']


    def parse(self, response):
        all_books = response.xpath('//article[@class="product_pod"]')
        
        for book in all_books:
            book_url = self.start_urls[0] + book.xpath('.//h3/a/@href').extract_first()
            yield scrapy.Request(book_url, callback=self.parse_book)

    def parse_book(self, response):
        print(response.status)
